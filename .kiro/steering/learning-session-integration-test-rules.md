---
inclusion: fileMatch
fileMatchPattern: '.kiro/specs/learning-session-integration-test/*'
---

# Learning Session Integration Test 전용 규칙

이 규칙은 learning-session-integration-test 스펙의 task 실행 시에만 적용됩니다.

## 테스트 코드 작성 규칙

### 파일 위치 및 명명
- 모든 테스트 파일은 `backend/tests/0820/` 폴더에 생성
- 테스트 파일명은 `test_` 접두사 사용 (예: `test_integration_learning_session.py`)
- 헬퍼 클래스나 유틸리티는 별도 파일로 분리 (예: `test_helpers.py`, `conftest.py`)

### 테스트 데이터 관리
- 모든 테스트 데이터는 `test_` 접두사를 사용하여 실제 데이터와 구분
- 테스트 완료 후 생성된 데이터는 자동으로 정리하지 않고 수동 삭제용 로그만 제공
- TestDataManager 클래스를 통해 일관된 테스트 데이터 생성

### LLM 호출 테스트 규칙 (실제 사용자 시나리오 기반)
- **실제 LLM 호출 필수**: 가상의 응답이나 모킹 사용 금지, 반드시 실제 OpenAI API 호출
- **순차적 플로우 테스트**: 실제 사용자처럼 단계별로 진행
  1. 세션 시작 → 이론 설명 요청 → LLM 응답 대기 및 수신
  2. 이론 내용 확인 후 → "다음 단계" 메시지 전송 → 퀴즈 출제 대기
  3. 퀴즈 데이터 수신 후 → 실제 답변 작성 → 답변 제출
  4. 평가 및 피드백 생성 대기 → 피드백 내용 수신 및 검증
- **응답 기반 동적 처리**: LLM 응답 내용을 파싱하여 다음 단계 결정
- **실제 대기 시간 포함**: LLM 응답 생성 시간을 고려한 충분한 대기 (최대 60초)
- **응답 내용 검증**: LLM이 생성한 실제 내용의 구조와 품질 기본 검증
- **API 키는 반드시 환경변수에서 읽어와야 함** (`os.getenv('OPENAI_API_KEY')`)
- **LLM 호출 실패 시 적절한 에러 핸들링 검증**
- **비용 감수 각오**: 실제 API 호출로 인한 비용 발생을 감안하고 테스트 진행

### 실제 사용자 시나리오 테스트 세부 규칙
- **이론 설명 단계**: 
  - 세션 시작 후 이론 설명이 완전히 생성될 때까지 대기
  - 생성된 이론 내용의 길이와 구조 검증 (최소 100자 이상)
  - 이론 설명 완료 후 "다음 단계" 또는 유사한 메시지로 진행
- **퀴즈 출제 단계**:
  - "다음 단계" 메시지 전송 후 퀴즈 생성까지 대기
  - 생성된 퀴즈의 타입(객관식/주관식) 확인
  - 퀴즈 데이터 구조 검증 (문제, 선택지, 정답 등)
- **답변 제출 단계**:
  - 퀴즈 타입에 맞는 실제 답변 작성 (정답/오답/부분정답)
  - 답변 제출 후 평가 및 피드백 생성까지 대기
  - 생성된 피드백의 품질과 적절성 기본 검증
- **세션 완료 단계**:
  - 피드백 확인 후 proceed/retry 결정
  - 세션 완료 처리 및 DB 저장 검증

### 데이터베이스 테스트 규칙
- 각 테스트는 독립적으로 실행 가능해야 함
- 트랜잭션 롤백보다는 테스트 데이터 생성/삭제 방식 사용
- DatabaseVerifier 클래스를 통해 일관된 DB 검증
- 테스트 실행 순서에 의존하지 않는 독립적인 테스트 작성

### 세션 상태 테스트 규칙
- 메모리 기반 세션 상태는 각 테스트마다 초기화
- 세션 만료 테스트는 실제 시간 대기 없이 모킹 사용
- TutorState 검증 시 핵심 속성만 확인 (과도한 내부 구조 검증 지양)

### 통합 테스트 플로우 규칙
- 전체 플로우 테스트는 단계별로 분리하여 디버깅 용이하게 작성
- 각 API 호출 후 응답 구조 검증 (API 문서 표준 형식 준수)
- 에러 케이스도 반드시 포함하여 견고성 검증

### 로깅 및 디버깅 규칙
- 테스트 실행 중 중요한 상태 변화는 로그로 출력
- **LLM 응답 내용 로깅**: 실제 생성된 이론, 퀴즈, 피드백 내용을 로그에 기록
- **단계별 진행 상황 로깅**: 각 API 호출과 응답 시점을 명확히 기록
- 실패한 테스트의 디버깅을 위해 충분한 컨텍스트 정보 제공
- 테스트 데이터 생성/삭제 내역은 별도 로그 파일에 기록

### 성능 및 안정성 규칙
- LLM 호출이 포함된 테스트는 타임아웃 설정 (60초로 연장)
- 네트워크 의존적인 테스트는 재시도 로직 포함
- 테스트 실행 시간이 긴 경우 진행 상황 표시
- **LLM 응답 대기 중 진행 상황 표시**: "LLM 응답 대기 중..." 등의 메시지 출력

## 코드 품질 규칙

### 한국어 주석 규칙
- 모든 테스트 함수에는 한국어로 테스트 목적 설명
- 복잡한 검증 로직에는 한국어 주석으로 의도 명시
- 에러 메시지는 원문 유지하되 한국어 설명 추가

### 코드 구조 규칙
- 테스트 함수는 Arrange-Act-Assert 패턴 준수
- 공통 로직은 헬퍼 함수나 픽스처로 분리
- 매직 넘버나 하드코딩된 값 사용 금지 (상수로 정의)

### 환경변수 및 보안 규칙
- 모든 민감한 정보는 환경변수에서 읽어오기
- 테스트 코드에도 실제 비밀번호나 API 키 하드코딩 금지
- .env 파일 사용 시 .env.example과 함께 관리