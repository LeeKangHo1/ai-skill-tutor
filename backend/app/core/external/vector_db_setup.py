# backend/app/core/external/vector_db_setup.py

import os
import sys
import json
import logging
from datetime import datetime
from typing import List, Dict, Any
from pathlib import Path

# Python ê²½ë¡œì— backend í´ë” ì¶”ê°€
current_file = os.path.abspath(__file__)
backend_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(current_file))))
if backend_dir not in sys.path:
    sys.path.insert(0, backend_dir)

from openai import OpenAI
from chromadb.utils import embedding_functions
from app.core.external.chroma_client import get_chroma_client


class VectorDBSetup:
    """
    ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸° êµ¬ì¶• ë° ë°ì´í„° ì‚½ì… í´ë˜ìŠ¤
    - JSON íŒŒì¼ë“¤ì„ ì½ì–´ì„œ ChromaDBì— ë²¡í„°í™”í•˜ì—¬ ì €ì¥
    - OpenAI text-embedding-3-large ëª¨ë¸ ì‚¬ìš©
    - ì‚½ì… ê¸°ë¡ì„ ë³„ë„ íŒŒì¼ì— ì €ì¥
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.chroma_client = get_chroma_client()
        
        # ê²½ë¡œ ì„¤ì •
        current_file = os.path.abspath(__file__)
        backend_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(current_file))))
        self.chapters_vec_path = os.path.join(backend_dir, 'data', 'chapters_vec')
        self.chapters_metadata_path = os.path.join(backend_dir, 'data', 'chapters', 'chapters_metadata.json')
        self.insertion_log_path = os.path.join(backend_dir, 'data', 'vector_insertion_log.json')
        
        # OpenAI ì„ë² ë”© í•¨ìˆ˜ ì„¤ì •
        self.embedding_function = embedding_functions.OpenAIEmbeddingFunction(
            api_key=os.getenv('OPENAI_API_KEY'),
            model_name="text-embedding-3-large"
        )
        
        # ì»¬ë ‰ì…˜ ì´ë¦„
        self.collection_name = "ai_tutor_contents"
        
    def setup_database(self) -> bool:
        """
        ì „ì²´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• í”„ë¡œì„¸ìŠ¤
        
        Returns:
            êµ¬ì¶• ì„±ê³µ ì—¬ë¶€
        """
        try:
            self.logger.info("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì‹œì‘")
            
            # 1. ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ (ì´ˆê¸°í™”)
            self._reset_collection()
            
            # 2. ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
            collection = self._create_collection()
            
            # 3. JSON íŒŒì¼ë“¤ ë¡œë“œ
            chapter_data_list = self._load_all_chapter_data()
            
            # 4. ì„¹ì…˜ ë©”íƒ€ë°ì´í„° ë¡œë“œ
            section_metadata = self._load_section_metadata()
            if not section_metadata:  # â† ì´ ì²´í¬ ì¶”ê°€
                self.logger.error("ì„¹ì…˜ ë©”íƒ€ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì„ë² ë”©ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                return False
            
            # 5. ë²¡í„° ë°ì´í„° ì‚½ì…
            insertion_results = self._insert_vector_data(collection, chapter_data_list, section_metadata)
            
            # 6. ì‚½ì… ê¸°ë¡ ì €ì¥
            self._save_insertion_log(insertion_results)
            
            self.logger.info(f"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì™„ë£Œ - ì´ {len(insertion_results)}ê°œ ì²­í¬ ì‚½ì…")
            return True
            
        except Exception as e:
            self.logger.error(f"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨: {str(e)}")
            return False
    
    def _reset_collection(self):
        """ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ"""
        try:
            self.chroma_client.delete_collection(self.collection_name)
            self.logger.info(f"ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ: {self.collection_name}")
        except Exception:
            # ì»¬ë ‰ì…˜ì´ ì—†ì–´ë„ ê´œì°®ìŒ
            self.logger.info(f"ì‚­ì œí•  ì»¬ë ‰ì…˜ ì—†ìŒ: {self.collection_name}")
    
    def _create_collection(self):
        """ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±"""
        collection = self.chroma_client.get_collection(
            collection_name=self.collection_name,
            embedding_function=self.embedding_function
        )
        self.logger.info(f"ìƒˆ ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ: {self.collection_name}")
        return collection
    
    def _load_all_chapter_data(self) -> List[Dict[str, Any]]:
        """chapters_vec í´ë”ì˜ ëª¨ë“  JSON íŒŒì¼ ë¡œë“œ"""
        all_chunks = []
        
        if not os.path.exists(self.chapters_vec_path):
            raise FileNotFoundError(f"chapters_vec í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {self.chapters_vec_path}")
        
        # JSON íŒŒì¼ë“¤ ì°¾ê¸°
        json_files = list(Path(self.chapters_vec_path).glob("*.json"))
        
        if not json_files:
            raise FileNotFoundError(f"chapters_vec í´ë”ì— JSON íŒŒì¼ì´ ì—†ìŒ: {self.chapters_vec_path}")
        
        # ê° JSON íŒŒì¼ ë¡œë“œ
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    chunk_data = json.load(f)
                    
                # íŒŒì¼ì´ ë¦¬ìŠ¤íŠ¸ì¸ì§€ ë‹¨ì¼ ê°ì²´ì¸ì§€ í™•ì¸
                if isinstance(chunk_data, list):
                    all_chunks.extend(chunk_data)
                else:
                    all_chunks.append(chunk_data)
                    
                self.logger.info(f"JSON íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {json_file.name}")
                
            except Exception as e:
                self.logger.error(f"JSON íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({json_file.name}): {str(e)}")
                continue
        
        self.logger.info(f"ì´ {len(all_chunks)}ê°œ ì²­í¬ ë¡œë“œ ì™„ë£Œ")
        return all_chunks
    
    def _load_section_metadata(self) -> Dict[str, str]:
        """ì„¹ì…˜ ì œëª© ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        section_titles = {}
        
        try:
            with open(self.chapters_metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # ì±•í„°ë³„ ì„¹ì…˜ ì œëª© ì¶”ì¶œ
            for chapter in metadata.get('chapters', []):
                chapter_num = chapter['chapter_number']
                for section in chapter.get('sections', []):
                    section_num = section['section_number']
                    section_title = section['section_title']
                    key = f"chapter_{chapter_num}_section_{section_num}"
                    section_titles[key] = section_title
            
            self.logger.info(f"ì„¹ì…˜ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(section_titles)}ê°œ")
            return section_titles
            
        except Exception as e:
            self.logger.error(f"ì„¹ì…˜ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return {}
    
    def _insert_vector_data(self, collection, chunks: List[Dict], section_metadata: Dict) -> List[Dict]:
        """ë²¡í„° ë°ì´í„° ì‚½ì…"""
        insertion_results = []
        
        for i, chunk in enumerate(chunks):
            try:
                # ì²­í¬ ê²€ì¦
                if not self._validate_chunk(chunk):
                    self.logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ ì²­í¬ ìŠ¤í‚µ: {chunk.get('id', 'unknown')}")
                    continue
                
                # ë©”íƒ€ë°ì´í„° ì¤€ë¹„
                metadata = {
                    "id": chunk["id"],
                    "chunk_type": chunk["chunk_type"],
                    "chapter": chunk["chapter"],
                    "section": chunk["section"],
                    "user_type": ",".join(chunk["user_type"]),  # ë¦¬ìŠ¤íŠ¸ë¥¼ ì‰¼í‘œë¡œ ì—°ê²°
                    "primary_keywords": ",".join(chunk["primary_keywords"]),  # ë¦¬ìŠ¤íŠ¸ë¥¼ ì‰¼í‘œë¡œ ì—°ê²°
                    "content_category": chunk["content_category"],
                    "content_quality_score": chunk["content_quality_score"],
                    "source_url": chunk["source_url"],
                    "generated_by_llm_name": chunk["generated_by_llm_name"]
                }
                
                # ì„¹ì…˜ ì œëª© ì¶”ê°€
                section_key = f"chapter_{chunk['chapter']}_section_{chunk['section']}"
                section_title = section_metadata.get(section_key, "ì œëª© ì—†ìŒ")
                
                # ChromaDBì— ì‚½ì…
                collection.add(
                    documents=[chunk["content"]],  # ë²¡í„°í™”ë  í…ìŠ¤íŠ¸
                    metadatas=[metadata],          # ë©”íƒ€ë°ì´í„°
                    ids=[chunk["id"]]              # ê³ ìœ  ID
                )
                
                # ì‚½ì… ê¸°ë¡ ì €ì¥
                insertion_results.append({
                    "id": chunk["id"],
                    "chunk_type": chunk["chunk_type"],
                    "user_type": chunk["user_type"],
                    "section_title": section_title,
                    "chapter": chunk["chapter"],
                    "section": chunk["section"],
                    "inserted_at": datetime.now().isoformat(),
                    "status": "success"
                })
                
                self.logger.debug(f"ì²­í¬ ì‚½ì… ì™„ë£Œ [{i+1}/{len(chunks)}]: {chunk['id']}")
                
            except Exception as e:
                self.logger.error(f"ì²­í¬ ì‚½ì… ì‹¤íŒ¨: {chunk.get('id', 'unknown')} - {str(e)}")
                
                # ì‹¤íŒ¨ ê¸°ë¡ë„ ì €ì¥
                insertion_results.append({
                    "id": chunk.get("id", "unknown"),
                    "chunk_type": chunk.get("chunk_type", "unknown"),
                    "user_type": chunk.get("user_type", []),
                    "section_title": "ì‚½ì… ì‹¤íŒ¨",
                    "chapter": chunk.get("chapter", 0),
                    "section": chunk.get("section", 0),
                    "inserted_at": datetime.now().isoformat(),
                    "status": "failed",
                    "error": str(e)
                })
                continue
        
        return insertion_results
    
    def _validate_chunk(self, chunk: Dict[str, Any]) -> bool:
        """ì²­í¬ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦"""
        required_fields = [
            "id", "chunk_type", "chapter", "section", 
            "user_type", "content", "primary_keywords"
        ]
        
        for field in required_fields:
            if field not in chunk or not chunk[field]:
                self.logger.warning(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
                return False
        
        # content ê¸¸ì´ ê²€ì¦ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ê²ƒ ì œì™¸)
        content_length = len(chunk["content"])
        if content_length < 100 or content_length > 3000:
            self.logger.warning(f"ë¶€ì ì ˆí•œ content ê¸¸ì´: {content_length}")
            return False
        
        return True
    
    def _save_insertion_log(self, insertion_results: List[Dict]):
        """ì‚½ì… ê¸°ë¡ì„ JSON íŒŒì¼ë¡œ ì €ì¥"""
        try:
            log_data = {
                "insertion_date": datetime.now().isoformat(),
                "total_chunks": len(insertion_results),
                "successful_insertions": len([r for r in insertion_results if r["status"] == "success"]),
                "failed_insertions": len([r for r in insertion_results if r["status"] == "failed"]),
                "results": insertion_results
            }
            
            with open(self.insertion_log_path, 'w', encoding='utf-8') as f:
                json.dump(log_data, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"ì‚½ì… ê¸°ë¡ ì €ì¥ ì™„ë£Œ: {self.insertion_log_path}")
            
        except Exception as e:
            self.logger.error(f"ì‚½ì… ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def get_insertion_status(self) -> Dict[str, Any]:
        """ë§ˆì§€ë§‰ ì‚½ì… ê¸°ë¡ ì¡°íšŒ"""
        try:
            if os.path.exists(self.insertion_log_path):
                with open(self.insertion_log_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                return {"status": "no_insertion_log"}
                
        except Exception as e:
            self.logger.error(f"ì‚½ì… ê¸°ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return {"status": "error", "message": str(e)}
    
    def verify_database(self) -> Dict[str, Any]:
        """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸"""
        try:
            collection = self.chroma_client.get_collection(
                collection_name=self.collection_name,
                embedding_function=self.embedding_function
            )
            
            total_count = collection.count()
            
            # chunk_typeë³„ í†µê³„
            chunk_type_stats = {}
            for chunk_type in ["core_concept", "analogy", "practical_example", "technical_detail"]:
                results = collection.get(where={"chunk_type": chunk_type})  
                count = len(results["ids"]) if results["ids"] else 0
                chunk_type_stats[chunk_type] = count

            # ì±•í„°ë³„ í†µê³„
            chapter_stats = {}
            for chapter in range(1, 9):  # 1~8ì±•í„°
                results = collection.get(where={"chapter": chapter})
                count = len(results["ids"]) if results["ids"] else 0
                chapter_stats[f"chapter_{chapter}"] = count
            
            return {
                "status": "success",
                "total_documents": total_count,
                "chunk_type_statistics": chunk_type_stats,
                "chapter_statistics": chapter_stats,
                "collection_name": self.collection_name,
                "embedding_model": "text-embedding-3-large"
            }
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
            return {
                "status": "error", 
                "message": str(e)
            }


def main():
    """ë²¡í„° DB êµ¬ì¶• ì‹¤í–‰ í•¨ìˆ˜"""
    print("=== AI íŠœí„° ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì‹œì‘ ===")
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # VectorDBSetup ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    db_setup = VectorDBSetup()
    
    # ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì‹¤í–‰
    success = db_setup.setup_database()
    
    if success:
        print("âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì„±ê³µ!")
        
        # êµ¬ì¶• ê²°ê³¼ í™•ì¸
        verification = db_setup.verify_database()
        print(f"ğŸ“Š ì´ ë¬¸ì„œ ìˆ˜: {verification.get('total_documents', 0)}")
        print(f"ğŸ“ˆ ì²­í¬ íƒ€ì…ë³„ í†µê³„: {verification.get('chunk_type_statistics', {})}")
        
    else:
        print("âŒ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨!")
        return False
    
    print("=== ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì™„ë£Œ ===")
    return True


if __name__ == "__main__":
    main()