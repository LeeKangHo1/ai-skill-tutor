# backend/test_subjective_feedback.py

import json
import os
import sys
from typing import Dict, Any

# ë°±ì—”ë“œ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€
backend_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, backend_dir)

from app.tools.analysis.evaluation_tools import determine_next_step
from app.tools.analysis.feedback_tools_chatgpt import evaluate_subjective_with_feedback


def load_subjective_quiz_from_chapter() -> Dict[str, Any]:
    """
    ì±•í„° íŒŒì¼ì—ì„œ ì£¼ê´€ì‹ í€´ì¦ˆ ë°ì´í„° ì°¾ê¸°
    
    Returns:
        ì£¼ê´€ì‹ í€´ì¦ˆ ë°ì´í„° ë˜ëŠ” None
    """
    try:
        # ì—¬ëŸ¬ ì±•í„°ì—ì„œ ì„¹ì…˜ 2ì˜ ì£¼ê´€ì‹ í€´ì¦ˆ ì°¾ê¸° (ë˜ëŠ” ì§ì ‘ ì±•í„° 5 ì„¹ì…˜ 2 íƒìƒ‰)
        target_chapters = [5]  # ì±•í„° 5 ìš°ì„  íƒìƒ‰
        for chapter_num in target_chapters:
            chapter_file = os.path.join(
                backend_dir, "data", "chapters", f"chapter_{chapter_num:02d}.json"
            )
            
            if not os.path.exists(chapter_file):
                continue
                
            with open(chapter_file, 'r', encoding='utf-8') as f:
                chapter_data = json.load(f)
            
            sections = chapter_data.get('sections', [])
            for section in sections:
                # ì„¹ì…˜ 2ì˜ ì£¼ê´€ì‹ í€´ì¦ˆë¥¼ ìš°ì„  ì°¾ê¸°
                if section.get('section_number') == 2:
                    quiz_data = section.get('quiz', {})
                    if quiz_data.get('type') == 'subjective':
                        print(f"âœ… ì±•í„° {chapter_num} ì„¹ì…˜ 2 ì£¼ê´€ì‹ í€´ì¦ˆ ë°œê²¬")
                        return quiz_data
        
        print("âŒ ì±•í„° 5 ì„¹ì…˜ 2 ì£¼ê´€ì‹ í€´ì¦ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return None
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None


def get_sample_subjective_quiz() -> Dict[str, Any]:
    """
    ì±•í„° 5 ì„¹ì…˜ 2 ì£¼ê´€ì‹ í€´ì¦ˆ ë°ì´í„° ë°˜í™˜
    """
    return {
        "type": "subjective",
        "question": "ì•„ë˜ì˜ ë°‹ë°‹í•œ í”„ë¡¬í”„íŠ¸ë¥¼ 'ë¶„ëŸ‰', 'ëŒ€ìƒ', 'ë¶„ìœ„ê¸°'ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì¡°ê±´ì„ 2ê°€ì§€ ì´ìƒ ì¶”ê°€í•˜ì—¬, í›¨ì”¬ ì¢‹ì€ ê²°ê³¼ë¬¼ì„ ì–»ì„ ìˆ˜ ìˆëŠ” í”„ë¡¬í”„íŠ¸ë¡œ ê°œì„ í•´ë³´ì„¸ìš”.\n\n[ê¸°ì¡´ í”„ë¡¬í”„íŠ¸]\n\"íšŒì‚¬ ì›Œí¬ìƒµì— ëŒ€í•œ ê³µì§€ ì´ë©”ì¼ì„ ì¨ì¤˜.\"",
        "sample_answer": "ì „ ì§ì›ì„ ëŒ€ìƒìœ¼ë¡œ í•œ íšŒì‚¬ ì›Œí¬ìƒµ ê³µì§€ ì´ë©”ì¼ì„ ì‘ì„±í•´ì¤˜. ì •ì¤‘í•˜ë©´ì„œë„ ì¹œê·¼í•œ í†¤ìœ¼ë¡œ 5-7ë¬¸ì¥ ë¶„ëŸ‰ìœ¼ë¡œ ì¨ì£¼ê³ , ì°¸ì„ ë…ë ¤ ë¬¸êµ¬ì™€ ë¬¸ì˜ì²˜ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•´ì¤˜.",
        "evaluation_criteria": [
            "êµ¬ì²´ì  ì¡°ê±´ 2ê°€ì§€ ì´ìƒ ì¶”ê°€",
            "ë¶„ëŸ‰, ëŒ€ìƒ, ë¶„ìœ„ê¸° ì¤‘ ìµœì†Œ 2ê°€ì§€ ëª…ì‹œ",
            "ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ëŒ€ë¹„ ëª…í™•í•œ ê°œì„ "
        ]
    }


def test_subjective_feedback():
    """
    ì£¼ê´€ì‹ í”¼ë“œë°± í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
    """
    print("="*80)
    print("ğŸ“‹ ì£¼ê´€ì‹ í”¼ë“œë°± í…ŒìŠ¤íŠ¸ ì‹œì‘ - ì±•í„° 5 ì„¹ì…˜ 2")
    print("(êµ¬ì²´ì  ì¡°ê±´ ì œì‹œ í”„ë¡¬í”„íŠ¸ ê°œì„ )")
    print("="*80)
    
    # í€´ì¦ˆ ë°ì´í„° ë¡œë“œ (ì‹¤ì œ íŒŒì¼ì—ì„œ ë˜ëŠ” ìƒ˜í”Œ ì‚¬ìš©)
    quiz_data = load_subjective_quiz_from_chapter()
    if not quiz_data:
        print("ğŸ”„ ì±•í„° 5 ì„¹ì…˜ 2 ìƒ˜í”Œ í€´ì¦ˆ ì‚¬ìš©")
        quiz_data = get_sample_subjective_quiz()
    
    # í€´ì¦ˆ ì •ë³´ ì¶œë ¥
    print("\nğŸ“ í€´ì¦ˆ ì •ë³´:")
    print(f"ë¬¸ì œ: {quiz_data.get('question', '')}")
    print(f"ìƒ˜í”Œ ë‹µì•ˆ: {quiz_data.get('sample_answer', '')}")
    print(f"í‰ê°€ ê¸°ì¤€:")
    for i, criteria in enumerate(quiz_data.get('evaluation_criteria', []), 1):
        print(f"  {i}. {criteria}")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤ (ì±•í„° 5 ì„¹ì…˜ 2 ê¸°ì¤€)
    test_cases = [
        {
            "name": "ìš°ìˆ˜í•œ ë‹µë³€ (80ì  ì´ìƒ ì˜ˆìƒ)",
            "answer": "ì „ ì§ì›ì„ ëŒ€ìƒìœ¼ë¡œ í•œ íšŒì‚¬ ì›Œí¬ìƒµ ê³µì§€ ì´ë©”ì¼ì„ ì‘ì„±í•´ì¤˜. ì •ì¤‘í•˜ë©´ì„œë„ ì¹œê·¼í•œ í†¤ìœ¼ë¡œ 5-7ë¬¸ì¥ ë¶„ëŸ‰ìœ¼ë¡œ ì¨ì£¼ê³ , ì°¸ì„ ë…ë ¤ ë¬¸êµ¬ì™€ ë¬¸ì˜ì²˜ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•´ì¤˜. ì œëª©ì—ëŠ” [í•„ë…]ì„ ë¶™ì´ê³  ì›Œí¬ìƒµ ì¼ì •ê³¼ ì¥ì†Œë„ ëª…ì‹œí•´ì¤˜.",
            "expected_score_range": "80-100ì "
        },
        {
            "name": "ë³´í†µ ë‹µë³€ (60-79ì  ì˜ˆìƒ)",
            "answer": "ì „ ì§ì› ëŒ€ìƒ íšŒì‚¬ ì›Œí¬ìƒµ ê³µì§€ ì´ë©”ì¼ì„ ì¹œê·¼í•œ í†¤ìœ¼ë¡œ 5ë¬¸ì¥ ì •ë„ë¡œ ì‘ì„±í•´ì¤˜. ì°¸ì„ ë…ë ¤ ë¬¸êµ¬ë„ í¬í•¨í•´ì¤˜.",
            "expected_score_range": "60-79ì "
        },
        {
            "name": "ë¶€ì¡±í•œ ë‹µë³€ (40-59ì  ì˜ˆìƒ)",
            "answer": "íšŒì‚¬ ì›Œí¬ìƒµ ê³µì§€ ì´ë©”ì¼ì„ ì •ì¤‘í•œ í†¤ìœ¼ë¡œ ì¨ì¤˜.",
            "expected_score_range": "40-59ì "
        },
        {
            "name": "ë§¤ìš° ë¶€ì¡±í•œ ë‹µë³€ (40ì  ë¯¸ë§Œ ì˜ˆìƒ)",
            "answer": "íšŒì‚¬ ì›Œí¬ìƒµ ì´ë©”ì¼ ì¢€ ë” ìì„¸íˆ ì¨ì¤˜.",
            "expected_score_range": "40ì  ë¯¸ë§Œ"
        }
    ]
    
    # ê° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n" + "="*60)
        print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i}: {test_case['name']}")
        print(f"ì˜ˆìƒ ì ìˆ˜: {test_case['expected_score_range']}")
        print("="*60)
        
        user_answer = test_case['answer']
        print(f"\nğŸ“ ì‚¬ìš©ì ë‹µë³€:")
        print(f"'{user_answer}'")
        
        # Beginner ì‚¬ìš©ì í…ŒìŠ¤íŠ¸
        print(f"\n--- Beginner ì‚¬ìš©ì í‰ê°€ ë° í”¼ë“œë°± ---")
        try:
            score, evaluation_detail = evaluate_subjective_with_feedback(
                quiz_data, user_answer, "beginner"
            )
            
            print(f"ğŸ“Š ì ìˆ˜: {score}ì ")
            
            # ë‹¤ìŒ ë‹¨ê³„ ê²°ì •
            next_step = determine_next_step(score, "subjective", 0)  # ì²« ë²ˆì§¸ ì‹œë„
            print(f"ğŸš¦ ë‹¤ìŒ ë‹¨ê³„: {next_step}")
            
            # ìƒì„¸ í”¼ë“œë°±
            detailed_feedback = evaluation_detail.get("detailed_feedback", "")
            if detailed_feedback:
                print(f"\nğŸ’¬ í”¼ë“œë°±:")
                print(detailed_feedback)
            
            # ê¸°ì¤€ë³„ ë¶„ì„
            criteria_analysis = evaluation_detail.get("criteria_analysis", {})
            if criteria_analysis:
                print(f"\nğŸ“‹ ê¸°ì¤€ë³„ ë¶„ì„:")
                for criteria, analysis in criteria_analysis.items():
                    print(f"  â€¢ {criteria}: {analysis}")
                    
        except Exception as e:
            print(f"âŒ Beginner í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        
        # Advanced ì‚¬ìš©ì í…ŒìŠ¤íŠ¸
        print(f"\n--- Advanced ì‚¬ìš©ì í‰ê°€ ë° í”¼ë“œë°± ---")
        try:
            score, evaluation_detail = evaluate_subjective_with_feedback(
                quiz_data, user_answer, "advanced"
            )
            
            print(f"ğŸ“Š ì ìˆ˜: {score}ì ")
            
            # ë‹¤ìŒ ë‹¨ê³„ ê²°ì •
            next_step = determine_next_step(score, "subjective", 0)
            print(f"ğŸš¦ ë‹¤ìŒ ë‹¨ê³„: {next_step}")
            
            # ìƒì„¸ í”¼ë“œë°±
            detailed_feedback = evaluation_detail.get("detailed_feedback", "")
            if detailed_feedback:
                print(f"\nğŸ’¬ í”¼ë“œë°±:")
                print(detailed_feedback)
                
        except Exception as e:
            print(f"âŒ Advanced í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        
        print(f"\n{'='*60}")
    
    print(f"\n" + "="*80)
    print("âœ… ì£¼ê´€ì‹ í”¼ë“œë°± í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("="*80)


def test_scoring_consistency():
    """
    ì ìˆ˜ ì¼ê´€ì„± í…ŒìŠ¤íŠ¸ - ê°™ì€ ë‹µë³€ì„ ì—¬ëŸ¬ ë²ˆ í‰ê°€í•˜ì—¬ ì¼ê´€ì„± í™•ì¸
    """
    print("\n" + "="*80)
    print("ğŸ”„ ì ìˆ˜ ì¼ê´€ì„± í…ŒìŠ¤íŠ¸ (ê°™ì€ ë‹µë³€ 3íšŒ í‰ê°€)")
    print("="*80)
    
    quiz_data = get_sample_subjective_quiz()
    test_answer = "ì „ ì§ì› ëŒ€ìƒ íšŒì‚¬ ì›Œí¬ìƒµ ê³µì§€ ì´ë©”ì¼ì„ ì¹œê·¼í•œ í†¤ìœ¼ë¡œ 5ë¬¸ì¥ ì •ë„ë¡œ ì‘ì„±í•´ì¤˜. ì°¸ì„ ë…ë ¤ ë¬¸êµ¬ë„ í¬í•¨í•´ì¤˜."
    
    print(f"í…ŒìŠ¤íŠ¸ ë‹µë³€: '{test_answer}'")
    
    scores = []
    for i in range(3):
        print(f"\n--- í‰ê°€ {i+1}íšŒì°¨ ---")
        try:
            score, evaluation_detail = evaluate_subjective_with_feedback(
                quiz_data, test_answer, "beginner"
            )
            scores.append(score)
            print(f"ì ìˆ˜: {score}ì ")
            
        except Exception as e:
            print(f"âŒ í‰ê°€ {i+1}íšŒì°¨ ì‹¤íŒ¨: {str(e)}")
    
    if scores:
        avg_score = sum(scores) / len(scores)
        score_range = max(scores) - min(scores)
        print(f"\nğŸ“Š ì ìˆ˜ í†µê³„:")
        print(f"  í‰ê·  ì ìˆ˜: {avg_score:.1f}ì ")
        print(f"  ì ìˆ˜ ë²”ìœ„: {min(scores)}~{max(scores)}ì  (ì°¨ì´: {score_range}ì )")
        print(f"  ì¼ê´€ì„±: {'ì¢‹ìŒ' if score_range <= 10 else 'ë³´í†µ' if score_range <= 20 else 'ë‚®ìŒ'}")


def main():
    """
    ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
    """
    print("ğŸ§ª ì£¼ê´€ì‹ í”¼ë“œë°± ìƒì„± í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í™˜ê²½ ë³€ìˆ˜ ì²´í¬
    if not os.getenv('OPENAI_API_KEY'):
        print("âš ï¸ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("âš ï¸ .env íŒŒì¼ì„ í™•ì¸í•˜ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return
    
    try:
        # ì£¼ê´€ì‹ í”¼ë“œë°± í…ŒìŠ¤íŠ¸
        # test_subjective_feedback()
        
        # ì ìˆ˜ ì¼ê´€ì„± í…ŒìŠ¤íŠ¸
        test_scoring_consistency()
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print("ğŸ”§ OpenAI API í‚¤ì™€ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    main()